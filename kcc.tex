% \documentclass[preprint]{kcc}
\documentclass{kcc}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% include additional packages you need to use
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% graphic, float package
\usepackage{graphicx}		% for setting images
\usepackage{float}			% for float objects
\usepackage{subfloat}		
\usepackage{subfigure}		% for adding several figures in a figure environment
\usepackage{lscape}			% for landscape type images or tables


\usepackage{enumitem}

% for compact section title spacing
% \usepackage[compact]{titlesec}


% mathmetical presentation
\usepackage{gensymb}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{exscale}
\usepackage{textcomp}		% extra symbols


% for circled number
\newcommand{\cl}[1]{\textcircled{\scriptsize #1}}


% package for using algorithmic presentation
\usepackage{algorithmic}
\usepackage{algorithm}
% customize algorithmic environment
\renewcommand{\algorithmicrequire}{\makebox[40px]{\hfill\textbf{Input :}}}
\renewcommand{\algorithmicensure}{\makebox[40px]{\hfill\textbf{Output :}}}

% array and table presentation
\usepackage{array}
\usepackage{tabulary}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{ctable}
\usepackage{booktabs}		% for typesetting tables at the level of publication		
							% do not use vertical rule
							
% set title, author, abstract
\title{서버리스 컴퓨팅: 문제점과 해결책}
\author{
고지원$^{\circ}$, 엄태건, 전병곤\\
%저자 소속 국문명 \\
\{alapha23, taegeonum\}@gmail.com, bgchun@snu.ac.kr
}
\engtitle{Serverless Computing: Pitfalls and Solutions}
\engauthor{
Zhiyuan Gao, Taegeon Um, Byung-Gon Chun\\
Department of Computer Science and Engineering, Seoul National University\\
%Author Affilication\\
}

\abstract{
Serverless computing is becoming more prevalent in terms of its high elasticity and fine-grained resource billing. Serverless research topics include intermediate data storage optimizations (e.g., Locus, Pocket), programming paradigm (e.g., Pyren) and exploration into its auto-scaling potential (e.g., Sprocket, ExCamera). This paper aims to provide an overview about serverless computing --- what are the benefits, what are the limitations. In addition to the pitfalls, we finally mention what has been mitigated about the limitations.
}

\begin{document}

\maketitle

\section{Introduction}

Serverless computing is a cloud computing execution model that frees developers from server management and machine resources allocation. With the help of a serverless programming framework, applications are defined as a set of functions (e.g., Lambda handlers) with access to a common data store. 
At each customer request, one serverless worker is dispatched to execute a proprietary task. Every task has a timeout while resource billing is based on execution duration and memory usage per request. Programming models are designed by different vendors such as AWS Lambda Function, Azure Functions and IBM Cloud Functions. Usually, serverless applications are stateless, but regarding stateful applications, customers can store intermediate data on cloud storages.

Compared with virtual machines (VMs), serverless computing simplifies application development in two ways.
First, serverless computing makes it easier to achieve auto-provisioning and auto-scaling. With VMs, auto-provisioning and auto-scaling relies on developers to implement but they are automatically achieved due to the benefit of serverless architecture. Second, serverless applications save the efforts of plenty of backend commitments needed by VMs-based services. Server management, handler isolation, load balancing and many other backend commitments are now handled by the cloud provider, meanwhile different customers only request a serverless worker from the common serverless pool.

As opposed to the offerings, serverless computing has its shortfalls. 
First, direct data transaction between serverless workers is not supported so a relay server is needed to ship intermediate data back and forth. 
Second, the slow initialization of serverless workers would add to the latency. Time-critical applications would have a longer latency due to the cold start of serverless workers.
Third, long-running complex event processing applications benefit less from serverless computing since sequential program logic cannot run parallelly. 
Fourth, despite the built-in fault-torlerant mechanisms, failed serverless workers have a longer latency and can be a straggler in the whole program pipeline. 
Fifth, severless computing raises security concerns because traditional security layers and mechanisms need to be ported to support serverless environments. 
Finally, serverless computing makes it harder to utilize specified hardware (e.g., GPU, TPU or a large RAM).

In this paper, we will discuss the pros and cons of serverless computing and also state the existing solutions to address its limitations.

\section{What serverless computing can do}

This section illustrates the offerings of serverless computing, due to which hosting web services or executing computations are simplified, with respect of the benifits: auto-scaling, high availability, real-time metrics and error aggregation and fine-grained resource billing plan.

\textbf{Auto-scaling} Cloud services achieve high elasticity through resource overprovisioning, overbooking and overcommitment based on their relatively long start delay~\cite{openLambda:2}. However, with a much shorter start delay~\cite{Sprocket:3}, serverless workers can easily and automatically be scaled when load suddenly increases. In a warm start, it can take less than one second to start a cloud function.~\cite{Kubernetes:16}

\textbf{Automated High Availability} Serverless functions have built-in availability and fault tolerance. Compute capacity is guaranteed by the cloud provider. For instance, every AWS region is a seperate geographic region, which contains several independent AWS availability zones. Although rare, a failure in one availability zone means failures of all instances in it. Developers can deploy resources across different availability zones to gain better availability.

\textbf{Real-time metrics and error aggregation} With help of serverless worker, we can easily monitor each serverless worker invoked. Memory issues, misconfiguration, timeout, runtime errors and exceptions can be recorded and reflected promptly with help of frameworks such as Dashbird, DATADOG, IOpipe and many others.

\textbf{Resource Billing Plan} Known as pay-by-use, users are not charged by idle handlers, which saving much overhead cost of container-based microservices. For AWS Lambda function, fine-grained resource billing allows more accurate calculation over resource use per user. The expenses are calculated in 100 ms increments. On the other hand, program logic with life span shorter than 100 ms is not benefited as much, (e.g., RPCs). One solution is to measure and control each serverless worker execution time to be longer than the cost calculation unit, saving cost from worker initialization and time rounding. 

\section{Limitations of serverless computing and solutions}

In spite of the offerings, serverless computing has its setbacks and limitations. As we will see in this section, current serverless computing restricts the ability to work efficiently with distributed computing resources.

\textbf{Intermediate data sharing} Current serverless computing solutions are restricted in terms of communication between serverless workers. 
Serverless workers cannot communicate with each other by design. Furthermore, serverless workers are running on isolated VMs, separated from data. As a consequnece, developers are expected to ship data back and forth to the serverless workers and among the workers. 
As for the solutions, there are plenty of mechanisms to ship data around. Communication between serverless workers are commonly achieved by a relay server, which handles intermediate data from workers, coordinates with program scheduler~\cite{Excamera:6} and sometimes implements fault-tolerance (e.g., Sprocket~\cite{Sprocket:3}, Pocket~\cite{Pocket:8}). 
Another solution is to communicate through a slow storage (e.g., AWS S3). Maintaining the state means writing the state to S3 and loading state back in subsequent calls. 
Access speed of existing solutions can be either too slow or too pricey, (e.g., S3, DynamoDB, ElastiCache Redis and Apache Crail). A plausible approach of the relay server is to raise job-attribute awareness in resource efficient scheduling. 
For instance, Locus~\cite{Shuffle:7} utilizes multi-tier storage to achieve resource-efficiency while Pocket~\cite{Pocket:8} raises object-size awareness.

\textbf{Cold start} Slow initialization time of serverless workers can add to the overall latency, and it is especially harmful to time-critical tasks. 
Warming up a new serverless worker includes starting the container, loading the programming language runtime, downloading libraries and packages and many others. Newly initialized serverless workers will mostly likely face a cold start. 
Solutions are divided into two predominant kinds. On one hand, developers can use a large number of parallel serverless workers to keep the some serverless function trigger frequent enough to keep 'warm'. For instance, ExCamera~\cite{Excamera:6} uses an identical independent parallel function to achieve warm start of every worker, and intermediate data is cached in its relay server. Even so, cold start latency is not prefectly resolved because: 
(1) there is a limit of workers in each AWS region, 
(2) ExCamera uses an identical Lambda function for all serverless workers, but not all applications could use an identical Lambda function, 
and (3) network bandwidth is shared by all workers in a VM. By default up to 20 workers of the same user reside on the same VM, so network of the same VM is shared by all the workers on it.
On the another hand, there are optimizations in the serverless runtime to achieve faster cold starting time~\cite{SOCK:18}. Those optimizations include:
(1) speed up container lifecycle, 
(2) fork from initialized processes runtime to shorten the start time, 
and (3) multi-tier caching to reuse initialization work across serverless workers.

%\textbf{Long-running complex event processing (CEP) benefits less from serverless computing} Not all kinds of functions are applicable to benefit from serverless computing. Sequential long-running program logic is inevitable in various applications, e.g., regular sequence operations. Serverless computing provides little guarantee in sequential execution of the functions and thus developers are encouraged to construct program logic in a highly parallel way. 
 
\textbf{Fault-tolerance} Cloud computing is pervasive but service outages still take place. Even though serverless functions have built-in fault-tolerance mechanisms implemented by the cloud vendor~\cite{WorkstationNetworks:14, Kubernetes:16}, failed workers have a high risk to be stragglers among a large number of workers. In case there are downstream task dependencies, a straggling worker might stall the entire pipeline~\cite{Straggler:4}. As a consequence, speculative execution~\cite{Mapreduce:5}, proactively cloning~\cite{Straggler:4}, worker pairing~\cite{Sprocket:3} are been applied to tackle this problem. Nevertheless, they all add complexity to the entire pipeline and consume more resources. 

\textbf{Security} On one hand, serverless computing is raising security concerns. Traditional security protections need to be ported to support serverless environments. Traditional layers such as endpoint protection cannot be deployed on serverless workers, because it is needed to build authentication into every function that gets accessed directly, even though serverless workers are ephemeral. Due to its ephemera, there is no session management built into serverless frameworks. For serverless computing, security monitoring becomes harder since existing solutions require a long-lived agent. On the other hand, serverless computing avoids some attacks due to its architecture by design. Many of the exploits today are targeted at vulnerable unpatch servers while serverless pushes the role to the cloud provider to keep servers patched. Additionally, DDoS becomes a billing issue thanks to elasticity of serverless computing. Nevertheless, serverless computing cannot resolve the application-level vulnerabilities inside the program logic. Static and dynamic security testing is still demanded.

\textbf{Harder to utilized specified hardware} Advantages by hardware specialization and GPU are not yet able to be utilized in serverless functions. Pervasive use of deep learning benefits from GPU, TPU or other hardware accelerators. Databases with large RAM based data structures such as SAP Hana also can not benefit from serverless computing. For instance, AWS Lambda function only offers 3 Gigabytes of RAM and is far from enough for application with high RAM demands. The lack of access to such hardware—along with appropriate pricing models limits the utility of serverless computing as a platform for software innovation~\cite{Kubernetes:16}.

\section{Conclusion}

Serverless computing differs from its predecessors in several essential ways: better autoscaling, fault-tolerance, security, strong isolation, platform flexibility and service ecosystem support. While some argue serverless computing is to some extent a rebranding of preceding offerings, we argue that standardization of programming model would help developers benefit from serverless computing. We could hopefully expect serverless to become more mainstream in enterprise applications and more integrated with other technologies, such as microservices and traditional application architectures.

\section{Acknowledgments}

This work was supported by Institute for Information \& communications Technology Promotion (IITP) grant funded by the Korea government (MSIT) (No.2015-0-00221, 다양한 분석을 고속 수행하는 단일화된 빅데이터 스택 개발).

\bibliographystyle{ieeetr}
\bibliography{ref}

\end{document}
